{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE CLASSIFICATION USING CIFAR10 DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\envs\\py35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#IMPORTING ESSENTIAL LIBRARIES\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Conv2D ,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING DATASET\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SAMPLE VISUALISATION OF SINGLE DATA\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(7,10))\n",
    "plt.subplot(330+1+1)\n",
    "plt.imshow(x_train[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NORMALISATION OF INPUT DATA\n",
    "x_train=x_train.astype('float32')\n",
    "x_test=x_test.astype('float32')\n",
    "x_train=x_train/255.0\n",
    "x_test=x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=keras.utils.to_categorical(y_train)\n",
    "y_test=keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LAYERS OF THE MODEL\n",
    "model=Sequential()\n",
    "model = Sequential()\n",
    "    \n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32,32,3)))    \n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))    \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "    \n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))    \n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "    \n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "    \n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(lr=1.0e-4), \n",
    "              metrics = ['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 463s 9ms/step - loss: 1.9304 - acc: 0.2904 - val_loss: 1.6272 - val_acc: 0.4147\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 447s 9ms/step - loss: 1.5843 - acc: 0.4202 - val_loss: 1.4715 - val_acc: 0.4682\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 447s 9ms/step - loss: 1.4697 - acc: 0.4642 - val_loss: 1.3694 - val_acc: 0.5012\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 531s 11ms/step - loss: 1.3909 - acc: 0.4974 - val_loss: 1.2962 - val_acc: 0.5335\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 352s 7ms/step - loss: 1.3287 - acc: 0.5258 - val_loss: 1.2356 - val_acc: 0.5585\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 343s 7ms/step - loss: 1.2832 - acc: 0.5408 - val_loss: 1.1801 - val_acc: 0.5842\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 339s 7ms/step - loss: 1.2328 - acc: 0.5608 - val_loss: 1.1398 - val_acc: 0.5992\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 340s 7ms/step - loss: 1.1936 - acc: 0.5773 - val_loss: 1.1138 - val_acc: 0.6097\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 340s 7ms/step - loss: 1.1541 - acc: 0.5918 - val_loss: 1.0675 - val_acc: 0.6274\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 340s 7ms/step - loss: 1.1186 - acc: 0.6046 - val_loss: 1.0304 - val_acc: 0.6449\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 341s 7ms/step - loss: 1.0900 - acc: 0.6161 - val_loss: 1.0064 - val_acc: 0.6519\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 339s 7ms/step - loss: 1.0558 - acc: 0.6279 - val_loss: 0.9786 - val_acc: 0.6630\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 340s 7ms/step - loss: 1.0306 - acc: 0.6396 - val_loss: 0.9598 - val_acc: 0.6741\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 339s 7ms/step - loss: 1.0039 - acc: 0.6476 - val_loss: 0.9329 - val_acc: 0.6788\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 341s 7ms/step - loss: 0.9802 - acc: 0.6559 - val_loss: 0.9158 - val_acc: 0.6825\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 340s 7ms/step - loss: 0.9550 - acc: 0.6659 - val_loss: 0.8982 - val_acc: 0.6887\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 339s 7ms/step - loss: 0.9378 - acc: 0.6715 - val_loss: 0.8773 - val_acc: 0.6969\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 338s 7ms/step - loss: 0.9153 - acc: 0.6778 - val_loss: 0.8764 - val_acc: 0.6940\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 342s 7ms/step - loss: 0.8976 - acc: 0.6862 - val_loss: 0.8513 - val_acc: 0.7084\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 341s 7ms/step - loss: 0.8778 - acc: 0.6929 - val_loss: 0.8335 - val_acc: 0.7103\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 339s 7ms/step - loss: 0.8596 - acc: 0.7004 - val_loss: 0.8273 - val_acc: 0.7132\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 351s 7ms/step - loss: 0.8413 - acc: 0.7066 - val_loss: 0.8105 - val_acc: 0.7201\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 434s 9ms/step - loss: 0.8294 - acc: 0.7107 - val_loss: 0.8150 - val_acc: 0.7165\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 457s 9ms/step - loss: 0.8122 - acc: 0.7185 - val_loss: 0.7901 - val_acc: 0.7272\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 447s 9ms/step - loss: 0.7998 - acc: 0.7221 - val_loss: 0.7919 - val_acc: 0.7264\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 453s 9ms/step - loss: 0.7806 - acc: 0.7265 - val_loss: 0.7745 - val_acc: 0.7347\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 365s 7ms/step - loss: 0.7674 - acc: 0.7336 - val_loss: 0.7721 - val_acc: 0.7307\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 342s 7ms/step - loss: 0.7560 - acc: 0.7353 - val_loss: 0.7668 - val_acc: 0.7347\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 344s 7ms/step - loss: 0.7394 - acc: 0.7424 - val_loss: 0.7506 - val_acc: 0.7412\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 349s 7ms/step - loss: 0.7300 - acc: 0.7461 - val_loss: 0.7432 - val_acc: 0.7431\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 375s 8ms/step - loss: 0.7163 - acc: 0.7494 - val_loss: 0.7414 - val_acc: 0.7403\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 339s 7ms/step - loss: 0.7087 - acc: 0.7508 - val_loss: 0.7259 - val_acc: 0.7475\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 338s 7ms/step - loss: 0.6913 - acc: 0.7568 - val_loss: 0.7130 - val_acc: 0.7537\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 362s 7ms/step - loss: 0.6821 - acc: 0.7630 - val_loss: 0.7099 - val_acc: 0.7531\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 371s 7ms/step - loss: 0.6651 - acc: 0.7691 - val_loss: 0.7085 - val_acc: 0.7530\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 379s 8ms/step - loss: 0.6580 - acc: 0.7718 - val_loss: 0.7027 - val_acc: 0.7593\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 348s 7ms/step - loss: 0.6478 - acc: 0.7735 - val_loss: 0.6984 - val_acc: 0.7595\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 345s 7ms/step - loss: 0.6347 - acc: 0.7780 - val_loss: 0.6882 - val_acc: 0.7631\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 343s 7ms/step - loss: 0.6241 - acc: 0.7817 - val_loss: 0.7185 - val_acc: 0.7556\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 342s 7ms/step - loss: 0.6134 - acc: 0.7856 - val_loss: 0.6768 - val_acc: 0.7641\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 343s 7ms/step - loss: 0.6030 - acc: 0.7895 - val_loss: 0.6789 - val_acc: 0.7647\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 347s 7ms/step - loss: 0.5941 - acc: 0.7949 - val_loss: 0.6812 - val_acc: 0.7633\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 340s 7ms/step - loss: 0.5856 - acc: 0.7946 - val_loss: 0.6724 - val_acc: 0.7706\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 342s 7ms/step - loss: 0.5776 - acc: 0.7986 - val_loss: 0.6675 - val_acc: 0.7706\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 349s 7ms/step - loss: 0.5704 - acc: 0.7998 - val_loss: 0.6554 - val_acc: 0.7725\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 344s 7ms/step - loss: 0.5584 - acc: 0.8043 - val_loss: 0.6580 - val_acc: 0.7719\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 338s 7ms/step - loss: 0.5446 - acc: 0.8084 - val_loss: 0.6503 - val_acc: 0.7738\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 351s 7ms/step - loss: 0.5399 - acc: 0.8103 - val_loss: 0.6713 - val_acc: 0.7720\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 339s 7ms/step - loss: 0.5334 - acc: 0.8120 - val_loss: 0.6596 - val_acc: 0.7739\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 340s 7ms/step - loss: 0.5222 - acc: 0.8170 - val_loss: 0.6779 - val_acc: 0.7730\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 340s 7ms/step - loss: 0.5170 - acc: 0.8182 - val_loss: 0.6559 - val_acc: 0.7767\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 338s 7ms/step - loss: 0.5074 - acc: 0.8219 - val_loss: 0.6462 - val_acc: 0.7793\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 345s 7ms/step - loss: 0.4978 - acc: 0.8255 - val_loss: 0.6452 - val_acc: 0.7787\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 338s 7ms/step - loss: 0.4889 - acc: 0.8273 - val_loss: 0.6437 - val_acc: 0.7822\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 352s 7ms/step - loss: 0.4830 - acc: 0.8302 - val_loss: 0.6455 - val_acc: 0.7813\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 394s 8ms/step - loss: 0.4826 - acc: 0.8301 - val_loss: 0.6385 - val_acc: 0.7851\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 616s 12ms/step - loss: 0.4714 - acc: 0.8317 - val_loss: 0.6401 - val_acc: 0.7820\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 559s 11ms/step - loss: 0.4649 - acc: 0.8377 - val_loss: 0.6406 - val_acc: 0.7828\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 557s 11ms/step - loss: 0.4580 - acc: 0.8390 - val_loss: 0.6431 - val_acc: 0.7832\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 376s 8ms/step - loss: 0.4503 - acc: 0.8405 - val_loss: 0.6362 - val_acc: 0.7865\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 343s 7ms/step - loss: 0.4436 - acc: 0.8440 - val_loss: 0.6394 - val_acc: 0.7852\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 341s 7ms/step - loss: 0.4371 - acc: 0.8459 - val_loss: 0.6378 - val_acc: 0.7841\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 342s 7ms/step - loss: 0.4280 - acc: 0.8491 - val_loss: 0.6386 - val_acc: 0.7842\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 337s 7ms/step - loss: 0.4225 - acc: 0.8528 - val_loss: 0.6378 - val_acc: 0.7871\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 338s 7ms/step - loss: 0.4172 - acc: 0.8520 - val_loss: 0.6694 - val_acc: 0.7781\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 343s 7ms/step - loss: 0.4129 - acc: 0.8534 - val_loss: 0.6350 - val_acc: 0.7882\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 338s 7ms/step - loss: 0.4095 - acc: 0.8546 - val_loss: 0.6324 - val_acc: 0.7878\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 337s 7ms/step - loss: 0.4037 - acc: 0.8553 - val_loss: 0.6309 - val_acc: 0.7887\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 338s 7ms/step - loss: 0.3937 - acc: 0.8613 - val_loss: 0.6350 - val_acc: 0.7884\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 336s 7ms/step - loss: 0.3923 - acc: 0.8598 - val_loss: 0.6353 - val_acc: 0.7890\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 336s 7ms/step - loss: 0.3870 - acc: 0.8625 - val_loss: 0.6341 - val_acc: 0.7859\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 338s 7ms/step - loss: 0.3787 - acc: 0.8651 - val_loss: 0.6460 - val_acc: 0.7890\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 338s 7ms/step - loss: 0.3748 - acc: 0.8673 - val_loss: 0.6475 - val_acc: 0.7888\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 337s 7ms/step - loss: 0.3691 - acc: 0.8674 - val_loss: 0.6389 - val_acc: 0.7894\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 338s 7ms/step - loss: 0.3602 - acc: 0.8716 - val_loss: 0.6367 - val_acc: 0.7907\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 339s 7ms/step - loss: 0.3590 - acc: 0.8723 - val_loss: 0.6378 - val_acc: 0.7920\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 339s 7ms/step - loss: 0.3504 - acc: 0.8747 - val_loss: 0.6382 - val_acc: 0.7894\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 339s 7ms/step - loss: 0.3473 - acc: 0.8768 - val_loss: 0.6349 - val_acc: 0.7900\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 338s 7ms/step - loss: 0.3454 - acc: 0.8781 - val_loss: 0.6384 - val_acc: 0.7897\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 338s 7ms/step - loss: 0.3357 - acc: 0.8811 - val_loss: 0.6451 - val_acc: 0.7920\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 342s 7ms/step - loss: 0.3349 - acc: 0.8792 - val_loss: 0.6343 - val_acc: 0.7944\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 339s 7ms/step - loss: 0.3308 - acc: 0.8817 - val_loss: 0.6397 - val_acc: 0.7951\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 338s 7ms/step - loss: 0.3262 - acc: 0.8838 - val_loss: 0.6375 - val_acc: 0.7938\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 342s 7ms/step - loss: 0.3214 - acc: 0.8845 - val_loss: 0.6442 - val_acc: 0.7927\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 347s 7ms/step - loss: 0.3141 - acc: 0.8880 - val_loss: 0.6389 - val_acc: 0.7942\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 349s 7ms/step - loss: 0.3106 - acc: 0.8884 - val_loss: 0.6541 - val_acc: 0.7953\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 374s 7ms/step - loss: 0.3073 - acc: 0.8902 - val_loss: 0.6416 - val_acc: 0.7935\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 340s 7ms/step - loss: 0.3009 - acc: 0.8923 - val_loss: 0.6534 - val_acc: 0.7905\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 351s 7ms/step - loss: 0.3021 - acc: 0.8929 - val_loss: 0.6520 - val_acc: 0.7947\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 364s 7ms/step - loss: 0.3009 - acc: 0.8920 - val_loss: 0.6579 - val_acc: 0.7944\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 370s 7ms/step - loss: 0.2934 - acc: 0.8947 - val_loss: 0.6686 - val_acc: 0.7910\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 347s 7ms/step - loss: 0.2932 - acc: 0.8940 - val_loss: 0.6459 - val_acc: 0.7940\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 357s 7ms/step - loss: 0.2880 - acc: 0.8976 - val_loss: 0.6622 - val_acc: 0.7935\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 360s 7ms/step - loss: 0.2779 - acc: 0.9013 - val_loss: 0.6526 - val_acc: 0.7919\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 365s 7ms/step - loss: 0.2869 - acc: 0.8985 - val_loss: 0.6516 - val_acc: 0.7949\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 362s 7ms/step - loss: 0.2774 - acc: 0.9006 - val_loss: 0.6583 - val_acc: 0.7920\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 358s 7ms/step - loss: 0.2761 - acc: 0.9017 - val_loss: 0.6570 - val_acc: 0.7931\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 358s 7ms/step - loss: 0.2719 - acc: 0.9022 - val_loss: 0.6584 - val_acc: 0.7951\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 357s 7ms/step - loss: 0.2688 - acc: 0.9047 - val_loss: 0.6610 - val_acc: 0.7934\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 355s 7ms/step - loss: 0.2625 - acc: 0.9051 - val_loss: 0.6655 - val_acc: 0.7969\n"
     ]
    }
   ],
   "source": [
    "model_details = model.fit(x_train, y_train,\n",
    "                    batch_size = 128, # number of samples per gradient update\n",
    "                    epochs = 100, # number of iterations\n",
    "                    validation_data= (x_test, y_test),\n",
    "                    callbacks=[checkpoint],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING THE MODEL\n",
    "model.save('final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\envs\\py35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "trainY = to_categorical(trainY)\n",
    "testY = to_categorical(testY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_norm = trainX.astype('float32')\n",
    "test_norm = testX.astype('float32')\n",
    "train_norm = train_norm / 255.0\n",
    "test_norm = test_norm / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING THE SAVED MODEL\n",
    "model = load_model('final.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 69.200\n"
     ]
    }
   ],
   "source": [
    "#TESTING ACCURACY ON TEST DATA\n",
    "_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "print('> %.3f' % (acc * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 83.394\n"
     ]
    }
   ],
   "source": [
    "#ACCURACY OF MODEL IN TRAIN DATA\n",
    "_, acc = model.evaluate(trainX, trainY, verbose=0)\n",
    "print('> %.3f' % (acc * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
